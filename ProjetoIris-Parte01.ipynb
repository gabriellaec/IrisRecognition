{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/gabriellaec/iris_recognition/blob/main/Visa%CC%83o_Computacional_Aula_04_(1)_(5).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nxY7Hh85nCjZ"
   },
   "source": [
    "# **Projeto 1**: Parte um\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bibliotecas importadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "xegy270QrDjP"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import cv2\n",
    "# from google.colab.patches import cv2_imshow\n",
    "import sys\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import os\n",
    "import G6_iris_recognition\n",
    "import random\n",
    "from skimage import measure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funções auxiliares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "v-yZigyXmHNT"
   },
   "outputs": [],
   "source": [
    "# Função para mostrar várias imagens em forma de uma grade\n",
    "\n",
    "def image_grid(images, cols = 2):\n",
    "    n_images = len(images)\n",
    "    fig = plt.figure()\n",
    "    for n, (image) in enumerate(images):\n",
    "        a = fig.add_subplot(cols, np.ceil(n_images/float(cols)), n + 1)\n",
    "        if image.ndim == 2:\n",
    "            plt.gray()\n",
    "        plt.imshow(image)\n",
    "    fig.set_size_inches(np.array(fig.get_size_inches()) * n_images)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtro de sobel\n",
    "\n",
    "def sobel(img_gray):\n",
    "    sobelx = cv.Sobel(img_gray,cv.CV_64F,1,0)\n",
    "    sobely = cv.Sobel(img_gray,cv.CV_64F,0,1)\n",
    "    return sobelx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para isolar o maior contorno de uma imagem\n",
    "\n",
    "def isolate_eye(img_gray):\n",
    "      T, thresh  = cv.threshold(img_gray,0,255,cv.THRESH_BINARY+cv.THRESH_OTSU)\n",
    "      img_contours, _ = cv.findContours(thresh, cv.RETR_TREE, cv.CHAIN_APPROX_SIMPLE)\n",
    "      cv.drawContours(img_gray, img_contours, -1, (0, 255, 0))\n",
    "      img_contours = sorted(img_contours, key=cv.contourArea)\n",
    "      for i in img_contours:\n",
    "        if cv.contourArea(i) > 1100:\n",
    "            break\n",
    "      mask = np.zeros(img_gray.shape[:2], np.uint8)\n",
    "      cv.drawContours(mask, [i],-1, 255, -1)\n",
    "      new_img = cv.bitwise_and(img_gray, img_gray, mask=mask)\n",
    "      eye = img_gray-new_img\n",
    "      return eye"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "3oXH_8VjOCIM"
   },
   "outputs": [],
   "source": [
    "# Função para detectar contornos (Canny)\n",
    "\n",
    "def auto_canny(image, sigma=0.33):\n",
    "    v = np.median(image)\n",
    "    lower = int(max(0, (1.0 - sigma) * v))\n",
    "    upper = int(min(255, (1.0 + sigma) * v))\n",
    "    edged = cv.Canny(image, lower, upper)\n",
    "    return edged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para isolar o olho e aplicar um filtro bilateral\n",
    "\n",
    "def blurred_eyes(img_gray):\n",
    "    outimg = cv.threshold(cv.medianBlur(img_gray, 3), 0, 255, cv.THRESH_BINARY + cv.THRESH_OTSU)[1]\n",
    "    img_gray[outimg==255]=255\n",
    "    processed_img = cv.bilateralFilter(img_gray,9,75,75)\n",
    "    return processed_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para aplicar um equalizador de histograma adaptativo (CLAHE)\n",
    "# E também faz um ROI para isolar o olho da imagem\n",
    "\n",
    "def adaptive_histeq(img_gray):\n",
    "      clahe = cv.createCLAHE(clipLimit = 2.0, tileGridSize=(8,8))\n",
    "      final_img = clahe.apply(img_gray) \n",
    "\n",
    "      edges = auto_canny(img_gray) \n",
    "      indices = np.where(edges != [0])\n",
    "\n",
    "      # cria uma nova imagem em branco\n",
    "      blank_img = np.zeros([480, 640],dtype=np.uint8)\n",
    "      blank_img[:] = 255  \n",
    "\n",
    "      h_max = max(indices[0])\n",
    "      h_min = min(indices[0])\n",
    "\n",
    "      w_max = max(indices[1])\n",
    "      w_min = min(indices[1])\n",
    "\n",
    "      roi=final_img[h_min:h_max,w_min:w_max]\n",
    "      blank_img[h_min:h_max,w_min:w_max]=roi\n",
    "      return blank_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função de faz um ROI com base nos contornos da imagem\n",
    "# Usada para isolar o olho\n",
    "\n",
    "def edges_roi(img_gray):\n",
    "      edges = auto_canny(img_gray) \n",
    "      indices = np.where(edges != [0])\n",
    "\n",
    "      # cria uma nova imagem em branco com as dimensões padrão\n",
    "      blank_img = np.zeros([480, 640],dtype=np.uint8)\n",
    "      blank_img[:] = 255  \n",
    "\n",
    "      h_max = max(indices[0])\n",
    "      h_min = min(indices[0])\n",
    "\n",
    "      w_max = max(indices[1])\n",
    "      w_min = min(indices[1])\n",
    "\n",
    "      roi=img_gray[h_min:h_max,w_min:w_max]\n",
    "      blank_img[h_min:h_max,w_min:w_max]=roi\n",
    "      return blank_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Função para aplicar um equalizador de histograma adaptativo (CLAHE)\n",
    "\n",
    "def apply_clahe(img_gray):\n",
    "      clahe = cv.createCLAHE(clipLimit = 2.0, tileGridSize=(8,8))\n",
    "      final_img = clahe.apply(img_gray) \n",
    "      return final_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para aplicar um equalizador de histograma adaptativo (CLAHE)\n",
    "\n",
    "def apply_intense_clahe(img_gray):\n",
    "      clahe = cv.createCLAHE(clipLimit = 5.0, tileGridSize=(12,12))\n",
    "      final_img = clahe.apply(img_gray) \n",
    "      return final_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função que aplica uma equalização do histograma no canal V da imagem\n",
    "\n",
    "def hsv_histeq(img_gray):\n",
    "    value=90\n",
    "    bgr = cv.cvtColor(img_gray, cv2.COLOR_GRAY2BGR)\n",
    "    hsv = cv.cvtColor(bgr, cv2.COLOR_BGR2HSV)\n",
    "    h, s, v = cv2.split(hsv)\n",
    "    imgeq=cv.equalizeHist(v)\n",
    "\n",
    "    final_hsv = cv2.merge((h, s, imgeq))\n",
    "    img = cv.cvtColor(final_hsv, cv2.COLOR_HSV2BGR)\n",
    "    img_gray = cv.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    return img_gray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função que tenta melhorar a equalização do histograma ao aplicar \n",
    "# um borramento na parte externa e destacar o olho\n",
    "\n",
    "def improved_histeq(img_gray):\n",
    "      imgeq=hsv_histeq(img_gray)\n",
    "      equalized_eye_original = isolate_eye(imgeq.astype(np.uint8))\n",
    "      equalized_eye=apply_clahe(equalized_eye_original)\n",
    "      blurc=cv.GaussianBlur(img_gray,(11,11),0)\n",
    "      \n",
    "      rows, cols = img_gray.shape\n",
    "      processed_img=np.zeros([rows,cols],dtype=np.uint8)\n",
    "      for l in range (rows):\n",
    "          for c in range (cols):\n",
    "            if equalized_eye_original[l,c] == 0:\n",
    "                processed_img[l,c] = blurc[l,c]\n",
    "            else:\n",
    "                processed_img[l,c] = (equalized_eye[l,c])\n",
    "      return processed_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função que usa uma máscara de binarização para remover o reflexo no olho\n",
    "\n",
    "# adaptado do tutorial: https://rcvaram.medium.com/glare-removal-with-inpainting-opencv-python-95355aa2aa52\n",
    "\n",
    "def create_mask(gray):\n",
    "    blurred = cv2.GaussianBlur( gray, (9,9), 0 )\n",
    "    _,thresh_img = cv2.threshold( blurred, 180, 255, cv2.THRESH_BINARY)\n",
    "    thresh_img = cv2.erode( thresh_img, None, iterations=2 )\n",
    "    thresh_img  = cv2.dilate( thresh_img, None, iterations=4 )\n",
    "    return thresh_img\n",
    "\n",
    "def remove_glare(img_gray):\n",
    "    blurred = cv2.GaussianBlur(img_gray, (9,9), 0)\n",
    "    mask=create_mask(blurred)\n",
    "    _,thresh_img = cv2.threshold( blurred, 180, 255, cv2.THRESH_BINARY)\n",
    "    dst = cv.inpaint(img_gray,mask,30,cv2.INPAINT_TELEA)\n",
    "\n",
    "    return dst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função que ajusta o canal V da imagem HSV para aumentar o brilho da imagem\n",
    "\n",
    "# Adaptada da fonte: https://www.ti-enxame.com/pt/python/como-mudar-rapidamente-o-brilho-da-imagem-com-python-opencv/1055807330/\n",
    "def increase_brightness(img):\n",
    "    value=80\n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "    h, s, v = cv2.split(hsv)\n",
    "\n",
    "    lim = 255 - value\n",
    "    v[v > lim] = 255\n",
    "    v[v <= lim] += value\n",
    "\n",
    "    final_hsv = cv2.merge((h, s, v))\n",
    "    img = cv2.cvtColor(final_hsv, cv2.COLOR_HSV2BGR)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kD3y_NsLglXA"
   },
   "source": [
    "## Processamento de imagens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na etapa a seguir, foram testadas diferentes técnicas de processamento de imagens, com o intuito de avaliar e selecionar aquelas com os melhores efeitos para deixar as íris em evidência ou minimizar os detalhes das partes externas que atrapalham o reconhecimento.\n",
    "\n",
    "Esta etapa foi dividida em filtros cuja função consiste em aumentar ou em diminuir os detalhes. Em seguida, foram aplicadas técnicas para melhor isolar a íris. Por fim, os melhores resultados foram selecionados para serem aplicados no modelo no próximo notebook (Parte Dois)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_imgs_list=[]\n",
    "\n",
    "# iteração 0: equalização do histograma \n",
    "equalized_imgs_list=[]\n",
    "\n",
    "#iteração 1: blur 1 (mais suave)\n",
    "blurred_imgs_list=[]\n",
    "\n",
    "# iteração 2: blur 2 (mais forte)\n",
    "blurred2_imgs_list=[]\n",
    "\n",
    "#iteração 7: blur muito intenso\n",
    "blurred3_imgs_list=[]\n",
    "\n",
    "#iteração 3: sobel\n",
    "sobel_list=[]\n",
    "\n",
    "# iteração 4: laplacian\n",
    "laplacian_list=[]\n",
    "\n",
    "#iteração 5: contornos\n",
    "edges_imgs_list=[]\n",
    "\n",
    "# iteração 6: isolando o olho\n",
    "eye_imgs_list=[]\n",
    "\n",
    "# iteração 8: recortando o olho da imagem aplicando uma máscara de threshold + filtro bilateral\n",
    "eyes2_list=[]\n",
    "matches_eyes2=0\n",
    "\n",
    "# iteração 9: CLAHE\n",
    "CLAHE_list=[]\n",
    "\n",
    "intense_CLAHE_list=[]\n",
    "\n",
    "convolution_product_list=[]\n",
    "\n",
    "improved_hist_list=[]\n",
    "\n",
    "hsv_histeq_list=[]\n",
    "\n",
    "denoised_list=[]\n",
    "\n",
    "detailEnhance_list=[]\n",
    "\n",
    "for iteration in range(15):\n",
    "    for dir in range(0,60):\n",
    "      for file in range(0,2):\n",
    "\n",
    "          src_path=f\"images2/00{dir:02d}/00{dir:02d}_0{file:02d}.bmp\"\n",
    "          # processamento da imagem\n",
    "          if os.path.exists(src_path):\n",
    "              img_gray = cv.imread(src_path, cv.IMREAD_GRAYSCALE) \n",
    "              imgeq=cv.equalizeHist(img_gray)\n",
    "\n",
    "              if iteration == 0:\n",
    "                  imgeq=cv.equalizeHist(img_gray)\n",
    "                  equalized_imgs_list.append(imgeq)\n",
    "                  original_imgs_list.append(img_gray)\n",
    "                    \n",
    "              elif iteration == 1:\n",
    "                  img_processed=cv.GaussianBlur(img_gray,(7,7),0) \n",
    "                  blurred_imgs_list.append(img_processed)\n",
    "                \n",
    "              elif iteration == 2:\n",
    "                  img_processed=cv.medianBlur(img_gray, 5)  \n",
    "                  blurred2_imgs_list.append(img_processed)\n",
    "\n",
    "              elif iteration == 3:\n",
    "                  img_processed=sobel(img_gray)\n",
    "                  sobel_list.append(img_processed.astype(np.uint8))\n",
    "              elif iteration == 4:\n",
    "                  img_processed = cv.Laplacian(imgeq,cv.CV_64F)\n",
    "#                   img_processed=img_gray+lap\n",
    "                  laplacian_list.append(img_processed.astype(np.uint8))\n",
    "                    \n",
    "              elif iteration == 5:\n",
    "                  img_processed=imgeq\n",
    "                  edges = auto_canny(imgeq)\n",
    "                  img_processed[edges==255] = (cv.medianBlur(img_gray, 17))[edges==255]\n",
    "                  edges_imgs_list.append(img_processed)\n",
    "                \n",
    "              elif iteration == 6:\n",
    "                   img_processed = isolate_eye(img_gray)\n",
    "                   eye_imgs_list.append(img_processed)\n",
    "                \n",
    "              elif iteration == 7:\n",
    "                   img_processed=blurred_eyes(img_gray)\n",
    "                   eyes2_list.append(img_processed)\n",
    "                \n",
    "              elif iteration == 8:\n",
    "                   img_processed=adaptive_histeq(img_gray)\n",
    "                   CLAHE_list.append(img_processed)\n",
    "                \n",
    "              elif iteration == 9:\n",
    "                   img_processed=improved_histeq(img_gray)\n",
    "                   img_processed=remove_glare(img_processed)\n",
    "                   improved_hist_list.append(img_processed)\n",
    "                \n",
    "              elif iteration == 10:\n",
    "                   img_processed=hsv_histeq(img_gray)\n",
    "                   img_processed=edges_roi(img_processed)\n",
    "                   hsv_histeq_list.append(img_processed)\n",
    "                    \n",
    "              elif iteration == 11:\n",
    "                   img=cv2.cvtColor(img_gray, cv2.COLOR_GRAY2BGR)\n",
    "                   img_processed= cv2.fastNlMeansDenoisingColored(img,None,10,10,7,21)\n",
    "                   img_processed = cv2.cvtColor(img_processed, cv2.COLOR_BGR2GRAY)\n",
    "                   denoised_list.append(img_processed)\n",
    "              elif iteration == 12:\n",
    "                   img_processed=cv.GaussianBlur(img_gray,(3,3),0) \n",
    "                   img_processed=apply_intense_clahe(img_processed)\n",
    "                   intense_CLAHE_list.append(img_processed)\n",
    "              elif iteration == 13:\n",
    "                   kernel = np.array([[0, -1, 0],\n",
    "                                       [-1, 7,-1],\n",
    "                                      [0, -1, 0]])\n",
    "                   image_sharp = cv2.filter2D(src=imgeq, ddepth=-1, kernel=kernel)\n",
    "                   convolution_product_list.append(image_sharp)\n",
    "              elif iteration == 14:\n",
    "                   cimg = cv2.cvtColor(img_gray,cv2.COLOR_GRAY2BGR)\n",
    "                   img_processed = cv.detailEnhance(cimg)\n",
    "                   img_gray = cv2.cvtColor(img_processed,cv2.COLOR_BGR2GRAY)             \n",
    "                   detailEnhance_list.append(img_gray)\n",
    "              \n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exemplos das imagens originais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "random_imgs = random.sample(original_imgs_list, 6)\n",
    "result = image_grid(np.array(random_imgs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Aumentando os detalhes das imagens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os filtros a seguir são muito úteis para as imagens em que as especificidades da íris são originalmente mais difíceis de identificar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Equalização do histograma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quando as cores da imagem estão muito próximas, é mais difícil perceber a divisão entre elas.\n",
    "\n",
    "A solução para isso é a equalização do histograma de cores, que é utilizada para melhor distribuir as cores da imagem e assim aumentar o contraste. Isso seria bom para o algoritmo conseguir perceber os contornos e as características da íris mais facilmente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "random_imgs = random.sample(equalized_imgs_list, 6)\n",
    "result = image_grid(np.array(random_imgs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos ver, agora os detalhes de cada íris são mais facilmente identificados. Além disso, fica mais fácil agora perceber os limites de onde a íris se encontra. Porém, a imagem parece ter ficado muito escura e com muito reflexo na pele que circunda o olho."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Equalização de histograma do canal V\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outro procedimento explorado foi a equalização do histograma aplicada em uma imagem HSV somente no canal V. Este canal é aquele responsável pelo brilho."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_imgs = random.sample(hsv_histeq_list, 6)\n",
    "result = image_grid(np.array(random_imgs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As imagens mostram que os resultados da equalização do histograma no canal V foram bastante semelhantes aos da primeira equalização aplicada, porém neste procedimento, a íris ficou mais clara."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Equalização do histograma adaptativa (CLAHE) mais suave"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com a equalização adaptativa do histograma, a imagem é dividida em uma grade M x N. Em seguida, é aplicada a equalização a cada célula da grade, resultando em uma imagem de saída de maior qualidade. Com isso, esse filtro consegue melhorar o contraste da imagem sem aumentar o ruído. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_imgs = random.sample(CLAHE_list, 6)\n",
    "result = image_grid(np.array(random_imgs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este filtro apresentou um desempenho muito bom, na medida que intensificou muito os detalhes da íris, sem destacar excessivamente as partes externas ao olho."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Equalização do histograma adaptativa (CLAHE) mais intensa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A função do CLAHE OpenCv possui 2 parâmetros:\n",
    "* **clipLimit:** Threshold para limitação de contraste\n",
    "* **tileGridSize:** Divide a imagem de entrada em blocos M x N e, em seguida, aplica a equalização do histograma a cada bloco local\n",
    "\n",
    "Nas imagens apresentadas a seguir, foi aumentado o parâmetro clipLimit, visando a aumentar ainda mais o contraste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "random_imgs = random.sample(intense_CLAHE_list, 6)\n",
    "result = image_grid(np.array(random_imgs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Percebe-se que com a mudança dos coeficientes da função, os detalhes da íris ficaram mais evidentes. No entanto, os cílios também ficaram com maior destaque, o que pode atrapalhar a identificação pelo modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tentativa de melhorar o resultado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para melhorar os resultados da equalização de histograma apresentada anteriormente, um procedimento de identificação do maior contorno foi aplicado, com o intuito de isolar o olho do restante da imagem. Após separada, a área de interesse foi clareada, por meio do ajuste do brilho da imagem. Nas áreas externas ao olho, foi aplicado um filtro de borramento, cujo intuito era diminuir os detalhes. Os resultados estão exibidos a seguir:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "random_imgs = random.sample(improved_hist_list, 6)\n",
    "result = image_grid(np.array(random_imgs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Percebe-se que o resultado não ficou tão bom como esperado, principalmente por conta de algumas falhas na máscara, que ao identificar o maior contorno, acaba por não isolar o olho completamente como seria ideal. Dessa forma, a imagem fica com algumas \"manchas\", que atrapalham a identificação."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtro de Sobel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O operador Sobel detecta bordas marcadas por mudanças repentinas na intensidade do pixel, sendo muito útil na identificação de contornos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_imgs = random.sample(sobel_list, 6)\n",
    "result = image_grid(np.array(random_imgs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As imagens não ficaram boas para a identificação após a aplicação deste filtro, com muito ruído e pouco destaque às íris."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detail Enhance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A função detailEnhance() da OpenCv é muito útil para aumentar os detalhes de uma imagem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_imgs = random.sample(detailEnhance_list, 6)\n",
    "result = image_grid(np.array(random_imgs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O filtro parece de fato ter aumentado a quantidade de detalhes na imagem, podendo assim ser útil para a identificação da íris."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtro de convolução"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nesta etapa, foi usada a função filter2D da OpenCv, que aplica uma matriz de convolução na imagem, visando a aumentar o contraste de um pixel com seus vizinhos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_imgs = random.sample(convolution_product_list, 6)\n",
    "result = image_grid(np.array(random_imgs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os resultados parecem ter ficados muito bons, já que os detahes da íris ficaram bem evidenciados e o reflexo da pele foi removido. Contudo, os cílios também parecem ter ficado muito em evidência."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtro Laplaciano"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este filtro ultiliza uma derivada segunda para detectar os contornos da imagem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "random_imgs = random.sample(laplacian_list, 6)\n",
    "result = image_grid(np.array(random_imgs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As imagens resultantes parecem não ser adequadas para o treinamento do modelo, já que há muito ruído e as íris não ficaram em destaque."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Diminuindo os detalhes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Diminuir os detalhes é muito útil para os casos de imagens que contém elementos atrapalhando a identificação das íris, como por exemplo cílios, sombrancelhas e reflexos na pele."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Borramento mais leve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primeiramente, foi aplicado um borramento mais leve, um filtro Gaussian Blur com uma matriz 7x7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_imgs = random.sample(blurred_imgs_list, 6)\n",
    "result = image_grid(np.array(random_imgs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos ver, o borramento foi bastante suave e permite que as peculiaridades da íris ainda sejam identificadas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Borramento mais intenso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para retirar ainda mais detalhes que atrapalham o reconhecimento, foi aplicado um filtro mais intenso para o borramento: o Median Blur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_imgs = random.sample(blurred2_imgs_list, 6)\n",
    "result = image_grid(np.array(random_imgs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O procedimento acima acabou tirando detalhes demais da íris, o que infuenciaria negativamente a identificação pelo modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remoção de ruídos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este filtro tem a função de remover os ruídos da imagem e foi aplicado com o intuito de diminuir o efeito dos cílios na identificação do modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "random_imgs = random.sample(denoised_list, 6)\n",
    "result = image_grid(np.array(random_imgs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os resultados não ficaram ideais, na medida que, apesar de os efeitos dos cílios terem sido de fato minimizados, muitos dos detalhes das íris acabaram sendo retirados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Borramento dos contornos da imagem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este procedimento foi aplicado visando a diminuir o impacto dos cílios, com o intuito de minimizar o impacto destes sobre a identificação da íris pelo módulo G6.\n",
    "\n",
    "Primeiramente, foi aplicado o filtro de Canny em uma imagem com a equalização do histograma (para melhor identificação da diferença entre cores, que evidencia os contornos). Em seguida, nas coordenadas dos contornos, foi aplicado um filtro de borramento muito intenso.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_imgs = random.sample(edges_imgs_list, 6)\n",
    "result = image_grid(np.array(random_imgs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As imagens mostram que os resultados não ficaram tão bons quanto esperado. O filtro suavizou muito pouco os contornos. Outro problema foi que alguns contornos dentro da íris foram afetados, o que poderia afetar negativamente o percentual de identificação do modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Isolando o olho"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Isolamento do olho por meio da binarização da imagem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para eliminar as partes externas ao olho que atrapalham a identificação e manter os elementos de interesse apenas, foi realizada uma binarização da imagem, com o intuito de identificar os olhos. Em seguida, as partes que não correspondiam às regiões de interesse foram eliminadas da figura, substituídas por um fundo branco. Por fim, foi aplicado um filtro bilateral suave, visando a borrar um pouco os cílios que atrapalhavam a identificação "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "random_imgs = random.sample(eyes2_list, 6)\n",
    "result = image_grid(np.array(random_imgs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os resultados não ficaram tão bons quanto esperado, pois a identificação de contornos não é perfeita e algumas lacunas podem ser identificadas dentro dos olhos. Apesar disso, a maior parte dos olhos parece ter sido isolada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Isolamento do olho por detecção do maior contorno"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para melhorar os resultados, foi aplicado um procedimento em que é realizada uma binarização da imagem seguida de uma identificação de contornos. Ao fim, apenas aquele elemento com o maior contorno é mantido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "random_imgs = random.sample(eye_imgs_list, 6)\n",
    "result = image_grid(np.array(random_imgs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como mostram as figuras, em alguns casos o procedimento funcionou muito bem, permitindo o isolamento completo do olho do restante da imagem. Contudo, em muitos casos, os contornos não ficaram muito bem definidos, fazendo com que algumas partes externas ao olho fossem mantidas na imagem. \n",
    "Ainda assim, as falhas resultantes do procedimento anterior foram em sua maior parte eliminadas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Isolando a íris por detecção de círculos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nesta etapa, foi aplicado o Hough Circles da OpenCv para detectar área correspondete à íris e destacar ela, minimizando os detalhes de outras partes da imagem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_isolated_eye = []\n",
    "processed_isolated_eye_details = []\n",
    "processed_isolated_eye_details_bright=[]\n",
    "\n",
    "for dir in range(0,60):\n",
    "      for file in range(0,3):\n",
    "        src_path=f\"images2/00{dir:02d}/00{dir:02d}_0{file:02d}.bmp\"\n",
    "        if os.path.exists(src_path):\n",
    "                    \n",
    "                    img_gray = cv.imread(src_path, cv.IMREAD_GRAYSCALE) \n",
    "                    \n",
    "                    # pré processamento da imagem\n",
    "                    img=cv.equalizeHist(img_gray)\n",
    "                    img = cv2.medianBlur(img,5)\n",
    "                    cimg = cv2.cvtColor(img,cv2.COLOR_GRAY2BGR)\n",
    "                    cimg_original = cv2.cvtColor(img_gray,cv2.COLOR_GRAY2BGR)\n",
    "                    img_final = cimg\n",
    "                    img_gray = cv.add(img,127,np.median(img_gray.flatten()))\n",
    "                    \n",
    "                    height,width = img.shape\n",
    "                    blank_image = cv.medianBlur(cv2.cvtColor(img_gray,cv2.COLOR_GRAY2BGR), 11)\n",
    "                    \n",
    "                    # detecção de círculos\n",
    "                    circles = cv2.HoughCircles(img,cv2.HOUGH_GRADIENT,1,10,param1=63,param2=70,minRadius=60,maxRadius=180)\n",
    "                    r = 0\n",
    "                    mask = np.zeros((height,width), np.uint8)\n",
    "                    if circles is not None:\n",
    "                        for i in circles[0,:]:\n",
    "                                mask = np.zeros((height,width), np.uint8)\n",
    "                                circle_img = cv2.circle(mask,(int(i[0]),int(i[1])),int(i[2]),(255,255,255),thickness=-1)\n",
    "                        masked_data = cv2.bitwise_and(img_final, img_final, mask=circle_img)\n",
    "                        _,thresh = cv2.threshold(mask,1,255,cv2.THRESH_BINARY)\n",
    "                        contours,_ = cv2.findContours(thresh,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n",
    "                        x,y,w,h = cv2.boundingRect(np.float32(contours[0]))\n",
    "                        crop = masked_data[y:y+h,x:x+w]\n",
    "\n",
    "                        blank_image = cv2.cvtColor(blank_image,cv2.COLOR_BGR2GRAY)\n",
    "                        masked_data_bright =increase_brightness(masked_data)\n",
    "                        masked_data = cv2.cvtColor(masked_data,cv2.COLOR_BGR2GRAY)\n",
    "                        masked_data_bright = cv2.cvtColor(masked_data_bright,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "                        for l in range(height):\n",
    "                            for c in range(width):\n",
    "                              if masked_data[l,c] != 0:\n",
    "                                blank_image[l,c]=masked_data[l,c]\n",
    "                        blank_image = cv2.cvtColor(blank_image,cv2.COLOR_GRAY2BGR)\n",
    "                        img_processed = (blank_image)\n",
    "                        processed_isolated_eye_details.append(img_processed)\n",
    "                                                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "random_imgs = random.sample(processed_isolated_eye_details, 6)\n",
    "result = image_grid(np.array(random_imgs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos ver, a íris ficou isolada na imagem, conforme esperado. No entanto, em alguns casos, o círculo desenhado não cobre a íris inteira, o que pode atrapalhar a identificação. Além disso, a parte externa à íris ficou clara demais na imagem, de forma que mal pode ser identificada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Melhorando os resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nas etapas a seguir, a área da íris foi destacada na própria imagem original. Primeiramente, foi aplicada uma equalização de histograma na área de interesse. Os resultados são mostrados abaixo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_isolated_eye = []\n",
    "processed_isolated_eye_details = []\n",
    "processed_isolated_eye_details_bright=[]\n",
    "\n",
    "circles_identified_images = []\n",
    "for dir in range(0,60):\n",
    "      for file in range(0,3):\n",
    "        src_path=f\"images2/00{dir:02d}/00{dir:02d}_0{file:02d}.bmp\"\n",
    "        if os.path.exists(src_path):\n",
    "                    img_gray = cv.imread(src_path, cv.IMREAD_GRAYSCALE) \n",
    "##### pré processamento da imagem #####\n",
    "                    img=cv.equalizeHist(img_gray)\n",
    "                    img = cv2.medianBlur(img,5)\n",
    "                    cimg = cv2.cvtColor(img,cv2.COLOR_GRAY2BGR)\n",
    "                    cimg_original = cv2.cvtColor(img_gray,cv2.COLOR_GRAY2BGR)\n",
    "                    img_final = cimg\n",
    "                    height,width = img.shape\n",
    "                    blank_image=cimg_original\n",
    "##### detecção de círculos #####\n",
    "                    circles = cv2.HoughCircles(img,cv2.HOUGH_GRADIENT,1,10,param1=63,param2=70,minRadius=90,maxRadius=180)\n",
    "                    r = 0\n",
    "                    mask = np.zeros((height,width), np.uint8)\n",
    "                    if circles is not None:\n",
    "                        for i in circles[0,:]:\n",
    "                                mask = np.zeros((height,width), np.uint8)\n",
    "                                circle_img = cv2.circle(mask,(int(i[0]),int(i[1])),int(i[2]),(255,255,255),thickness=-1)\n",
    "\n",
    "##### deixando a íris em evidência #####\n",
    "                        masked_data = cv2.bitwise_and(img_final, img_final, mask=circle_img)\n",
    "                        _,thresh = cv2.threshold(mask,1,255,cv2.THRESH_BINARY)\n",
    "                        contours,_ = cv2.findContours(thresh,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n",
    "                        x,y,w,h = cv2.boundingRect(np.float32(contours[0]))\n",
    "                        crop = masked_data[y:y+h,x:x+w]\n",
    "                        blank_image = cv2.cvtColor(blank_image,cv2.COLOR_BGR2GRAY)\n",
    "                        masked_data = cv2.cvtColor(masked_data,cv2.COLOR_BGR2GRAY)\n",
    "                        hist_hsv = hsv_histeq(img_gray)\n",
    "                        for l in range(height):\n",
    "                            for c in range(width):\n",
    "                              if masked_data[l,c] != 0:\n",
    "                                blank_image[l,c]=hist_hsv[l,c]\n",
    "                        blank_image = cv2.cvtColor(blank_image,cv2.COLOR_GRAY2BGR)\n",
    "                        circles_identified_images.append(blank_image)\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "random_imgs = random.sample(circles_identified_images, 6)\n",
    "result = image_grid(np.array(random_imgs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As imagens acima mostraram resultados interessantes. O procedimento não funcionou muito bem para todas as imagens, porém, para aquelas em que a íris foi identificada corretamente, a região de interesse obteve maior destaque. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O mesmo procedimento acima foi aplicado agora com a equalização de histograma adaptativa:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "processed_isolated_eye = []\n",
    "processed_isolated_eye_details = []\n",
    "processed_isolated_eye_details_bright=[]\n",
    "\n",
    "circles_identified_images = []\n",
    "for dir in range(0,60):\n",
    "      for file in range(0,3):\n",
    "        src_path=f\"images2/00{dir:02d}/00{dir:02d}_0{file:02d}.bmp\"\n",
    "        if os.path.exists(src_path):\n",
    "                    img_gray = cv.imread(src_path, cv.IMREAD_GRAYSCALE) \n",
    "##### pré processamento da imagem #####\n",
    "                    img=cv.equalizeHist(img_gray)\n",
    "                    img = cv2.medianBlur(img,5)\n",
    "                    cimg = cv2.cvtColor(img,cv2.COLOR_GRAY2BGR)\n",
    "                    cimg_original = cv2.cvtColor(img_gray,cv2.COLOR_GRAY2BGR)\n",
    "                    img_final = cimg\n",
    "                    height,width = img.shape\n",
    "                    blank_image=cimg_original\n",
    "                    \n",
    "##### detecção de círculos #####\n",
    "                    circles = cv2.HoughCircles(img,cv2.HOUGH_GRADIENT,1,10,param1=63,param2=70,minRadius=90,maxRadius=180)\n",
    "                    r = 0\n",
    "                    mask = np.zeros((height,width), np.uint8)\n",
    "                    if circles is not None:\n",
    "                        for i in circles[0,:]:\n",
    "                                mask = np.zeros((height,width), np.uint8)\n",
    "                                circle_img = cv2.circle(mask,(int(i[0]),int(i[1])),int(i[2]),(255,255,255),thickness=-1)\n",
    "\n",
    "##### deixando a íris em evidência #####\n",
    "                        masked_data = cv2.bitwise_and(img_final, img_final, mask=circle_img)\n",
    "                        _,thresh = cv2.threshold(mask,1,255,cv2.THRESH_BINARY)\n",
    "                        contours,_ = cv2.findContours(thresh,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n",
    "                        x,y,w,h = cv2.boundingRect(np.float32(contours[0]))\n",
    "                        crop = masked_data[y:y+h,x:x+w]\n",
    "                        blank_image = cv2.cvtColor(blank_image,cv2.COLOR_BGR2GRAY)\n",
    "                        masked_data = cv2.cvtColor(masked_data,cv2.COLOR_BGR2GRAY)\n",
    "                        clahe = apply_clahe(img_gray)\n",
    "                        for l in range(height):\n",
    "                            for c in range(width):\n",
    "                              if masked_data[l,c] != 0:\n",
    "                                blank_image[l,c]=clahe[l,c]\n",
    "                        blank_image = cv2.cvtColor(blank_image,cv2.COLOR_GRAY2BGR)\n",
    "                        circles_identified_images.append(blank_image)\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_imgs = random.sample(circles_identified_images, 6)\n",
    "result = image_grid(np.array(random_imgs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este filtro realçou ainda mais os detalhes da íris, o que tende a facilitar a identificação."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Isolando e aumentando a íris"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O código a seguir detecta os círculos correspondentes à íris e recorta o restante da imagem, de forma a dar zoom  nas partes de interesse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_isolated_eye = []\n",
    "processed_isolated_eye_sharp = []\n",
    "processed_isolated_eye_bright = []\n",
    "processed_isolated_eye_sharp_bright = []\n",
    "clahe_eye=[]\n",
    "for dir in range(0,60):\n",
    "      for file in range(0,3):\n",
    "        src_path=f\"images2/00{dir:02d}/00{dir:02d}_0{file:02d}.bmp\"\n",
    "        if os.path.exists(src_path):\n",
    "                \n",
    "                if os.path.exists(src_path):\n",
    "                    img_gray = cv.imread(src_path, cv.IMREAD_GRAYSCALE) \n",
    "                img=cv.equalizeHist(img_gray)\n",
    "                img = cv2.medianBlur(img,5)\n",
    "                cimg = cv2.cvtColor(img,cv2.COLOR_GRAY2BGR)\n",
    "                img_final = cimg\n",
    "                circles = cv2.HoughCircles(img,cv2.HOUGH_GRADIENT,1,10,param1=63,param2=70,minRadius=60,maxRadius=180)\n",
    "                height,width = img.shape\n",
    "                blank_image = np.zeros((height,width,3), np.uint8)\n",
    "                r = 0\n",
    "                mask = np.zeros((height,width), np.uint8)\n",
    "                if circles is not None:\n",
    "                    for i in circles[0,:]:\n",
    "                          h1=(int(i[1])-int(i[2]))-50\n",
    "                          h2=int(i[1])+int(i[2])+50\n",
    "                          w1=(int(i[0])-int(i[2]))-50\n",
    "                          w2=int(i[0])+int(i[2])+50\n",
    "\n",
    "                          height = abs(h2-h1)\n",
    "                          width=abs(w2-w1)\n",
    "                          blank_image = np.zeros((height,width,3), np.uint8)\n",
    "\n",
    "                          blank_image = img_final[int(h1):int(h2),int(w1):int(w2)]\n",
    "                          hb,wb,cb = blank_image.shape\n",
    "                          h,w = img_gray.shape\n",
    "                          if h>1 and w >1 and hb>1 and cb>1 and blank_image is not None:\n",
    "                              try:\n",
    "                                    quadro = np.zeros((h,w,3), np.uint8)\n",
    "                                    quadro[:]=255\n",
    "                                    ratio_height = h/hb\n",
    "                                    ratio_width = w/wb\n",
    "                                    ratio = min(ratio_width,ratio_height)\n",
    "                                    w_new=int(ratio*wb)\n",
    "                                    h_new=int(ratio*hb)\n",
    "                                    resized = cv.resize(blank_image, (w_new,h_new))\n",
    "                                    quadro=resized\n",
    "                                    print(image.shape)\n",
    "                              except:\n",
    "                                    pass\n",
    "                    kernel = np.array([[0, -1, 0],\n",
    "                                       [-1, 5,-1],\n",
    "                                      [0, -1, 0]])\n",
    "                    if hb>0 and cb>0:\n",
    "                            image_sharp = cv2.filter2D(src=quadro, ddepth=-1, kernel=kernel)\n",
    "                            cimg = cv2.cvtColor(image_sharp,cv2.COLOR_BGR2GRAY)\n",
    "                            processed_isolated_eye_sharp.append(cimg)\n",
    "                            img_processed=quadro\n",
    "                            image_sharp=increase_brightness(img_processed)\n",
    "                            cimg = cv2.cvtColor(img_processed,cv2.COLOR_BGR2GRAY)\n",
    "                            processed_isolated_eye_sharp_bright.append(cimg)\n",
    "\n",
    "                            img_processed = cv.detailEnhance(quadro)\n",
    "                            cimg = cv2.cvtColor(img_processed,cv2.COLOR_BGR2GRAY)\n",
    "                            processed_isolated_eye.append(cimg)\n",
    "                            \n",
    "                            img_processed=increase_brightness(img_processed)\n",
    "                            cimg = cv2.cvtColor(img_processed,cv2.COLOR_BGR2GRAY)\n",
    "                            processed_isolated_eye_bright.append(cimg)\n",
    "                            cimg = cv2.cvtColor(quadro,cv2.COLOR_BGR2GRAY)\n",
    "                            clahe=apply_clahe(cimg)\n",
    "                            clahe_eye.append(clahe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_imgs = random.sample(processed_isolated_eye_sharp, 6)\n",
    "result = image_grid(np.array(random_imgs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_imgs = random.sample(processed_isolated_eye_sharp, 6)\n",
    "result = image_grid(np.array(random_imgs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_imgs = random.sample(processed_isolated_eye_sharp_bright, 6)\n",
    "result = image_grid(np.array(random_imgs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_imgs = random.sample(processed_isolated_eye, 6)\n",
    "result = image_grid(np.array(random_imgs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O procedimento de dar zoom na íris não foi benéfico para facilitar a identificação da imagem. Isso porque em muitas imagens, partes importantes para a idenficação foram cortadas. Além disso, ao aumentar o tamanho da íris, os parâmetros do modelo para a identificação dos círculos não se adequam mais. Isso piora muito a identificação."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Escolha dos melhores procedimentos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com base nos resultados apresentados acima, os filtros que apresentaram os melhores resultados foram:\n",
    "* Equalização do histograma no canal V\n",
    "* Borramento mais suave (gaussiano)\n",
    "* Equalização de histograma adaptativa (CLAHE) - com o coeficiente mais suave e o mais intenso\n",
    "* Aplicação do filtro de convolução \n",
    "* Intensificação de detalhes pela função detailEnhance\n",
    "* Destaque da íris na imagem com equalização de histograma adaptativa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estes procedimentos serão aplicados sequencialmente para a identificação do modelo no Notebook da parte 02."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "Visão_Computacional_Aula_04_(1) (5).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
